Inspecting checkpoint: /root/projects/data/SpectralGPT+.pth
============================================================
✓ Checkpoint loaded successfully

1. TOP-LEVEL KEYS:
------------------------------
  model: dict with 271 items
  optimizer: dict with 2 items
  epoch: <class 'int'>
  scaler: dict with 5 items
  args: <class 'argparse.Namespace'>

2. MODEL ARCHITECTURE:
------------------------------

  POS_EMBED_SPATIAL: (1 parameters)
    pos_embed_spatial: torch.Size([1, 256, 768])

  POS_EMBED_TEMPORAL: (1 parameters)
    pos_embed_temporal: torch.Size([1, 4, 768])

  MASK_TOKEN: (1 parameters)
    mask_token: torch.Size([1, 1, 512])

  DECODER_POS_EMBED_SPATIAL: (1 parameters)
    decoder_pos_embed_spatial: torch.Size([1, 256, 512])

  DECODER_POS_EMBED_TEMPORAL: (1 parameters)
    decoder_pos_embed_temporal: torch.Size([1, 4, 512])

  PATCH_EMBED: (2 parameters)
    patch_embed.proj.bias: torch.Size([768])
    patch_embed.proj.weight: torch.Size([768, 1, 3, 8, 8])

  BLOCKS: (192 parameters)
    blocks.0.attn.k.bias: torch.Size([768])
    blocks.0.attn.k.weight: torch.Size([768, 768])
    blocks.0.attn.proj.bias: torch.Size([768])
    blocks.0.attn.proj.weight: torch.Size([768, 768])
    blocks.0.attn.q.bias: torch.Size([768])
    ... and 187 more

  NORM: (2 parameters)
    norm.bias: torch.Size([768])
    norm.weight: torch.Size([768])

  DECODER_EMBED: (2 parameters)
    decoder_embed.bias: torch.Size([512])
    decoder_embed.weight: torch.Size([512, 768])

  DECODER_BLOCKS: (64 parameters)
    decoder_blocks.0.attn.k.bias: torch.Size([512])
    decoder_blocks.0.attn.k.weight: torch.Size([512, 512])
    decoder_blocks.0.attn.proj.bias: torch.Size([512])
    decoder_blocks.0.attn.proj.weight: torch.Size([512, 512])
    decoder_blocks.0.attn.q.bias: torch.Size([512])
    ... and 59 more

  DECODER_NORM: (2 parameters)
    decoder_norm.bias: torch.Size([512])
    decoder_norm.weight: torch.Size([512])

  DECODER_PRED: (2 parameters)
    decoder_pred.bias: torch.Size([192])
    decoder_pred.weight: torch.Size([192, 512])

3. ARCHITECTURE DETAILS:
------------------------------
  Number of transformer blocks: 12
  Separable positional embeddings:
    Spatial patches: 256
    Temporal patches: 4
  -> This is likely a SpectralGPT/Video ViT model
  3D Patch embedding: 1 -> 768
    Patch size: temporal=3, spatial=8x8
  -> This is a 3D/Temporal model

4. PARAMETER COUNT:
------------------------------
  Total parameters: 98,640,320
  Model size: ~376.3 MB (float32)

5. SPECIAL COMPONENTS:
------------------------------
  ✓ Decoder (MAE/Autoencoder)
  ✓ Mask token (MAE)

6. DETAILED INFO SAVED:
------------------------------
  Layer details saved to: SpectralGPT+_architecture.json